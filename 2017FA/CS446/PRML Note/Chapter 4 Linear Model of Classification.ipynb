{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model of Classification\n",
    "\n",
    "Generally, we consider a hyper-plane to be a decision surface\n",
    "\n",
    "$$z = \\mathbf{w}^T\\mathbf{x} + w_0$$\n",
    "\n",
    "To introduce non-linear component, we can use activation function \n",
    "$$y(\\mathbf{x}) = f(\\mathbf{w}^T\\mathbf{x} + w_0)$$\n",
    "\n",
    "## Discriminant Function\n",
    "### Two classes\n",
    "\n",
    "Linear discriminant has the most simple form of \n",
    "$$y(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{x} + w_0$$\n",
    "\n",
    "then the distance from original point to discriminant plane is \n",
    "$$\\frac{\\mathbf{w}^T\\mathbf{x}}{||\\mathbf{w}||} = -\\frac{w_0}{||\\mathbf{x}||}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\mathbf{x} = \\mathbf{x}_{\\bot} + r\\frac{\\mathbf{w}}{||\\mathbf{w}||}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$r = \\frac{y(\\mathbf{x})}{||\\mathbf{w}||}$$\n",
    "\n",
    "### Multiple classes\n",
    "There are several ways to extend two classes algorithm to multiple classes:\n",
    "* Use $K - 1$ classifiers to solve $k - 1$ one-versus-the-rest classification problems\n",
    "* Use $\\frac{K(K - 1)}{2}$ classifiers to solve $\\frac{K(K - 1)}{2}$ one-versus-one classification problems.\n",
    "* Use a K classes discriminant function by using $K$ linear functions of form\n",
    "$$y_k(\\mathbf{x}) = \\mathbf{w}^T_k\\mathbf{x} + w_{k0}$$\n",
    "\n",
    "Then if for all $j \\ne k$ there is $y_k > y_i$, the $\\mathbf{x}$ will be classify to class $C_k$.\n",
    "\n",
    "Then the hyperplanes has form $$(\\mathbf{w}_k - \\mathbf{w}_j)^T + (w_{k0} - w_{j0}) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to learn a discriminant function:\n",
    "* Least Mean Sum for Classification\n",
    "* Fisher linear discriminant function\n",
    "* Perceptron\n",
    "\n",
    "### Least Mean Sum for Classification\n",
    "\n",
    "Suppose we describe class $C_k$ by using linear model\n",
    "$$y_k(\\mathbf{x}) = \\mathbf{w}^T_k\\mathbf{x}_{k0}$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\mathbf{y}(\\mathbf{x}) = \\tilde{\\mathbf{W}}^T\\tilde{\\mathbf{x}}$$\n",
    "\n",
    "then we have error function\n",
    "\n",
    "$$E_D(\\tilde{\\mathbf{W}}) = \\frac{1}{2}Tr\\{(\\tilde{\\mathbf{X}}\\tilde{\\mathbf{W}} - \\mathbf{T})^T(\\tilde{\\mathbf{X}}\\tilde{\\mathbf{W}} - \\mathbf{T})\\}$$\n",
    "\n",
    "so $$\\tilde{\\mathbf{W}} = (\\tilde{\\mathbf{X}})^{\\dagger}\\mathbf{T}$$\n",
    "\n",
    "then we get the discriminant function\n",
    "$$\\mathbf{y}(\\mathbf{x}) = \\mathbf{T}^T(\\tilde{\\mathbf{X}})^{\\dagger} \\tilde{\\mathbf{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Linear Discriminant function\n",
    "\n",
    "Consider the occasion of two classes first.\n",
    "\n",
    "Suppose we have $y = \\mathbf{w}^T\\mathbf{x}$, let those $x$ that $y \\geq -w_0$ to be class $C_1$ and the rest to be $C_2$, then we have $$\\mathbf{m}_1 = \\frac{1}{N_1}\\sum_{n \\in C_1}\\mathbf{x}_n, \\mathbf{m}_2 = \\frac{1}{N_2}\\sum_{n \\in C_2}\\mathbf{x}_n$$\n",
    "\n",
    "then we can measure the extent two classes are seperated by maximizing\n",
    "$$m_2 - m_1 = \\mathbf{w}^T(\\mathbf{m}_2 - \\mathbf{m}_1)$$\n",
    "\n",
    "while restraining $||\\mathbf{w}|| = 1$. Since by using this method, when the covariance matrix and diagnalized matrix have too much differences, there will be a large overlapping on the projection to the line that connects the means of two classes.\n",
    "\n",
    "Thus, Fisher brought up the idea to maximize a function to make the gap between two classes larger with make the variance in each class smaller, so that it minimize the overlapping between classes.\n",
    "\n",
    "Denote the in-class variance by $$s_k^2 = \\sum_{n \\in C_k}(y_n - m_k)^2$$\n",
    "\n",
    "define $$J(\\mathbf{w}) = \\frac{(m_2 - m_1)^2}{s_1^2 + s_2^2}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$J(\\mathbf{w}) = \\frac{\\mathbf{w^TS_Bw}}{w^TS_Ww}$$ in which, the between-class covariance matrix is\n",
    "\n",
    "$$\\mathbf{S_B} = (\\mathbf{m_2 - m_1})(\\mathbf{m_2 - m_1})^T$$\n",
    "\n",
    "and the within-class covariance matrix is\n",
    "$$\\mathbf{S_W} = \\sum_{n \\in C_1}(\\mathbf{m_n - m_1})(\\mathbf{m_n - m_1})^T + \\sum_{n \\in C_2}(\\mathbf{m_n - m_2})(\\mathbf{m_n - m_2})^T$$\n",
    "\n",
    "then by calculating the derivative respect to $\\mathbf{w}$, we get \n",
    "$$(\\mathbf{w^TS_Bw})\\mathbf{S_Ww} = (\\mathbf{w^TS_Ww})\\mathbf{S_Bw}$$\n",
    "\n",
    "which gives\n",
    "$$\\mathbf{w} \\propto \\mathbf{S}_W^{-1}(\\mathbf{w}_2 - \\mathbf{w}_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "Consider a nonlinear activation function\n",
    "$$f(a) = \n",
    "\\begin{cases}\n",
    "    +1 & a \\geq 0\\\\\n",
    "    -1 & a < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "that maps $\\mathbf{w}^T\\phi(\\mathbf{x})$ to $\\{-1, +1\\}$.\n",
    "\n",
    "So we can define a error function $$E_P(\\mathbf{w}) = -\\sum_{n \\in \\mathcal{M}}\\mathbf{w}^T\\phi_nt_n$$\n",
    "\n",
    "so that we can use SGD to minimize the error function by\n",
    "\n",
    "$$\\mathbf{w}^{\\tau + 1} = \\mathbf{w}^{\\tau} - \\eta\\nabla E_P(\\mathbf{w}) = \\mathbf{w}^{\\tau} - \\eta\\phi_nt_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def f(x, y):\n",
    "    return x ** 3 + 10 * x ** 2 + 5 * y ** 2 + 5 * x * y\n",
    "\n",
    "def delta(x, y):\n",
    "    return np.array([3 * x ** 2 + 20 * x + 5 * y, 10 * y + 5 * x])\n",
    "\n",
    "alpha = 0.085\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = np.linspace(-10, 10, 100)\n",
    "X,Y = np.meshgrid(x, y)\n",
    "plt.contour(X, Y, f(X, Y), 40, alpha=1)\n",
    "#plt.clabel(C, inline=True, fontsize=10)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "initX = 2\n",
    "initY = 7\n",
    "init = np.array([initX, initY])\n",
    "path = []\n",
    "path.append(init)\n",
    "oldinit = init.copy()\n",
    "delta0 = delta(oldinit[0], oldinit[1])\n",
    "while la.norm(delta0) >= 1e-6:\n",
    "    newinit = oldinit - alpha * delta(oldinit[0], oldinit[1])\n",
    "    path.append(newinit)\n",
    "    plt.plot(np.array([oldinit[0], newinit[0]]), np.array([oldinit[1], newinit[1]]), 'b-')\n",
    "    oldinit = newinit.copy()\n",
    "    delta0 = delta(oldinit[0], oldinit[1])\n",
    "    \n",
    "for p in path:\n",
    "    plt.plot(p[0], p[1], 'b-')\n",
    "print(len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Probabilistic Generative Model\n",
    "\n",
    "Consider the problem of two classes first. Then the posterior probability of class $C_1$ is \n",
    "\n",
    "$$p(C_1 \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x} \\mid C_1)}{p(\\mathbf{x} \\mid C_1)p(C_1) + p(\\mathbf{x} \\mid C_2)p(C_2)} = \\frac{1}{1 + \\exp(-a)} = \\sigma(a)$$\n",
    "\n",
    "in which, $$a = \\ln \\frac{p(\\mathbf{x} \\mid C_1)p(C_1)}{p(\\mathbf{x} \\mid C_2)p(C_2)}$$\n",
    "\n",
    "and we have **Logistic Sigmoid Function:** \n",
    "$$\\sigma(a) = \\frac{1}{1 + \\exp(-a)}$$\n",
    "\n",
    "it is easy to prove that:\n",
    "\n",
    "* $\\sigma(-a) = 1 - \\sigma(a)$\n",
    "* Logistic Sigmoid Function's inverse function is **logit function**:\n",
    "$$a = \\ln \\left(\\frac{\\sigma}{1 - \\sigma}\\right)$$\n",
    "\n",
    "For occasion of $K > 2$ classes we have **softmax function**:\n",
    "$$p(C_k \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x} \\mid C_k)p(C_k)}{\\sum_{j}p(\\mathbf{x} \\mid C_j)p(C_j)} = \\frac{\\exp(a_k)}{\\sum_j \\exp(a_j)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x112d4b3c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112ca8b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "y = sigmoid(x)\n",
    "plt.grid()\n",
    "plt.plot(x, y, 'b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Suppose there are two classes under Gaussian-like distribution, and $p(C_1) = \\pi$ and $p(C_2) = 1 - \\pi$, so\n",
    "$$p(\\mathbf{x}_n, C_1) = p(C_1)p(\\mathbf{x}_n \\mid C_1) = \\pi\\mathcal{N}(\\mathbf{x}_n \\mid \\mu_1, \\Sigma)$$\n",
    "\n",
    "$$p(\\mathbf{x}_n, C_2) = p(C_2)p(\\mathbf{x}_n \\mid C_2) = (1 - \\pi)\\mathcal{N}(\\mathbf{x}_n \\mid \\mu_2, \\Sigma)$$\n",
    "\n",
    "so the likelihood function is $$p(\\mathbf{t, X} \\mid \\pi, \\mu_1, \\mu_2, \\Sigma) = \\prod_{n = 1}^N [\\pi\\mathcal{N}(\\mathbf{x}_n \\mid \\mu_1, \\Sigma)]^{t_n}[(1 - \\pi)\\mathcal{N}(\\mathbf{x}_n \\mid \\mu_2, \\Sigma)]^{1 - t_n}$$\n",
    "\n",
    "then we want to maximize the part of logit likelihood function that is relavant to $\\pi$, which is\n",
    "\n",
    "$$\\sum_{n = 1}^N \\{t_n\\ln\\pi + (1 - t_n)\\ln(1 - \\pi)\\}$$\n",
    "\n",
    "so we get $$\\pi = \\frac{1}{N}\\sum_{n = 1}^N t_n = \\frac{N_1}{N_1 + N_2}$$\n",
    "\n",
    "or maximize $$\\sum_{n = 1}^N t_n \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{\\mu}_1, Sigma) = \\frac{1}{2}\\sum_{n = 1}^Nt_n(\\mathbf{x}_n - \\mathbf{\\mu}_1)^T\\Sigma^{-1}(\\mathbf{x}_n - \\mathbf{\\mu}_1)$$ respect to $mu_1$, so we get\n",
    "\n",
    "$$\\mu_1 = \\frac{1}{N_1}\\sum_{n = 1}^N t_n\\mathbf{x}_n$$\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$\\mu_2 = \\frac{1}{N_2}\\sum_{n = 1}^N t_n\\mathbf{x}_n$$\n",
    "\n",
    "or when we want to maximize $$-\\frac{N}{2}\\ln|\\Sigma| - \\frac{N}{2}Tr\\{\\Sigma^{-1}\\mathbf{S}\\}$$\n",
    "\n",
    "in which $$\\mathbf{S} = \\frac{N_1}{N}\\mathbf{S_1} + \\frac{N_2}{N}\\mathbf{S_2}$$\n",
    "\n",
    "that $$\\mathbf{S}_k = \\frac{1}{N_k} \\sum_{n \\in C_k}(\\mathbf{x}_n - \\mu_k)(\\mathbf{x}_n - \\mu_k)^T$$\n",
    "\n",
    "so $\\Sigma = S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "If we have dataset $t_n, \\phi_n$, with likelihood function $$p(\\mathbf{t \\mid w}) = \\prod_{n = 1}^N y_n^{t_n}\\{1 - y_n\\}^{1 - t_n}$$\n",
    "\n",
    "so by taking the logits, we have **cross-entropy error function**\n",
    "$$E(\\mathbf{w}) = -\\sum_{n = 1}^N \\{t_n\\ln y_n + (1 - t_n)\\ln (1 - y_n)\\}$$\n",
    "\n",
    "in which, $$y_n = \\sigma(\\mathbf{w}^T\\phi_n)$$\n",
    "\n",
    "so that $$\\nabla E(\\mathbf{w}) = \\sum_{n = 1}^N (y_n - t_n)\\phi_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3\n",
       "0  0  4   8  12\n",
       "1  1  5   9  13\n",
       "2  2  6  10  14\n",
       "3  3  7  11  15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
