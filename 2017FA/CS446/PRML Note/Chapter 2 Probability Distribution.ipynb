{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Probability Distribution\n",
    "## Binary Variable\n",
    "    \n",
    "**Bernoulli Distribution:** $\\mathrm{Bern}(x \\mid \\mu) = \\mu^x(1 - \\mu)^{1 - x}$\n",
    "* $\\mathbb{E}[x] = \\mu$\n",
    "* $\\mathrm{var}[x] = \\mu(1 - \\mu)$\n",
    "* Likelihood Function: $$p(\\mathcal{D} | \\mu) = \\prod_{n = 1}^N \\mu^{x_n}(1 - \\mu)^{1 - x_n}$$\n",
    "\n",
    "So $\\mu_{ML} = \\frac{m}{N}$\n",
    "\n",
    "**Binomial Distribution:** $\\mathrm{Bin}(m \\mid N, \\mu) = \\binom{N}{m} \\mu^m(1-\\mu)^{N - m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x103759e80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x101f80a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "samples = np.random.binomial(10, 0.25, 100000)\n",
    "plt.hist(samples, normed=True, range=(0, 10))\n",
    "plt.xlabel('m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to prove that binomial has:\n",
    "* $\\mathbb{E}[m] = N\\mu$\n",
    "* $\\mathrm{var}[m] = N\\mu(1 - \\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beta Distribution:** $$\\mathrm{Beta}(\\mu \\mid a, b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)}\\mu^{a - 1}(1 - \\mu)^{b - 1}$$\n",
    "\n",
    "$$\\Gamma(x) = \\int^{\\infty}_0 u^{x - 1}e^{-u}du$$\n",
    "\n",
    "* $\\mathbb{E}[\\mu] = \\frac{a}{a + b}$\n",
    "* $\\mathrm{var}[\\mu] = \\frac{ab}{(a + b)^2(a + b + 1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Variable\n",
    "If we use $\\mu_k$ to represent the probability that $x_k = 1$, then\n",
    "$$p(\\mathbf{x} \\mid \\mathbf{\\mu}) = \\prod_{k = 1}^K \\mu_k^{x_k}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\\mathbb{E}[\\mathbf{x} \\mid \\mathbf{\\mu}] = \\sum_{\\mathbf{x}} p(\\mathbf{x} \\mid \\mathbf{\\mu}) = \\mathbf{\\mu}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Distribution\n",
    "$$\\mathcal{N}(x \\mid \\mu, \\sigma^2) = \\frac{1}{(2\\pi\\sigma^2)^{\\frac{1}{2}}} \\exp\\{-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\}$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\mathcal{N}(\\mathbf{x} \\mid \\mu, \\sigma^2) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}} \\frac{1}{|\\Sigma|^{\\frac{1}{2}}} \\exp\\{-\\frac{1}{2\\sigma^2}(\\mathbf{x} - \\mu)^T\\Sigma^{-1} (\\mathbf{x} - \\mu)\\}$$\n",
    "\n",
    "so\n",
    "\n",
    "* $\\mathbb{E}[\\mathbf{x}] = \\mathbf{\\mu}$\n",
    "* $\\mathbb{E}[\\mathbf{xx}^T] = \\mathbf{\\mu\\mu}^T + \\mathbf{\\Sigma}$\n",
    "* $\\mathrm{var}[\\mathbf{x}] = \\mathbf{\\Sigma}$, which is called the covariance matrix.\n",
    "\n",
    "Since $\\Sigma$ has $\\frac{D(D+1)}{2}$ free parameters, $\\mu$ has D free parameters, so we usually only consider **diagonal covariance matrix** $\\Sigma = \\mathrm{diag}(\\sigma^2_i)$ or **isotropic covariance matrix** $\\Sigma = \\sigma^2\\mathbf{I}$\n",
    "\n",
    "### Conditional Gaussian Distribution\n",
    "Suppose $\\mathbf{x}$ is a D-dimension vector under Gaussian Distribution, then divide $\\mathbf{x}$ into two disjoint subsets. So\n",
    "$$\\mathbf{x} = \\binom{\\mathbf{x}_a}{\\mathbf{x}_b}$$\n",
    "$$\\mathbf{\\mu} = \\binom{\\mathbf{\\mu}_a}{\\mathbf{\\mu}_b}$$\n",
    "$$\\Sigma = \\begin{pmatrix}\n",
    "               \\Sigma_{aa} & \\Sigma_{ab}\\\\\n",
    "               \\Sigma_{ba} & \\Sigma_{bb}\\\\\n",
    "           \\end{pmatrix}$$\n",
    "In many cases, it is convenient to use **precision matrix** $$\\Lambda = \\Sigma^{-1}$$\n",
    "\n",
    "So $$\\mu_{a \\mid b} = \\mu_a + \\Sigma_{ab}\\Sigma^{-1}_{bb}(\\mathbf{x}_b - \\mu_a)$$\n",
    "\n",
    "$$\\Sigma_{a \\mid b} = \\Sigma_{aa} + \\Sigma_{ab}\\Sigma^{-1}_{bb}\\Sigma_{ba}$$\n",
    "\n",
    "### Marginal Gaussian Distribution\n",
    "$$p(\\mathbf{x}_a) = \\int p(\\mathbf{x}_a, \\mathbf{x}_b)d\\mathbf{x}_b$$\n",
    "* $\\mathbb{E}[\\mathbf{x}_a] = \\mathbf{\\mu}_a$\n",
    "* $\\mathrm{cov}[\\mathbf{x}_a] = \\Sigma_{aa}$\n",
    "\n",
    "### Mixture Gaussian Distribution\n",
    "\n",
    "Since Gaussian distribution only gives one peak, which sometimes does not reflect the real condition of given datasets, so we can use the linear combination of Gaussian distributions.\n",
    "\n",
    "$$p(\\mathbf{x}) = \\sum_{k = 1}^K \\pi_k\\mathcal{N}(\\mathbf{x} \\mid \\mu_k, \\Sigma_k) = \\sum_{k = 1}^K p(k)p(\\mathbf{x} \\mid k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nonparametric Methods\n",
    "\n",
    "Suppose there is a unknown probability density distribution in D dimension $p(\\mathbf{x})$. Consider a small region $\\mathcal{R}$ that contains $\\mathbf{x}$, whose mass is \n",
    "$$P = \\int_{\\mathcal{R}}p(\\mathbf{x})d\\mathbf{x}$$\n",
    "\n",
    "Suppose there are $N$ samples, then \n",
    "$$\\mathrm{Bin}(K \\mid N, P) = \\binom{N}{K}P^K(1 - P)^{N - K}$$\n",
    "\n",
    "which has\n",
    "* $\\mathbb{E}[\\frac{K}{N}] = P$\n",
    "* $\\mathrm{var}[\\frac{K}{N}] = \\frac{P(1 - P)}{N}$\n",
    "\n",
    "gives that there will be a peak near mean value when there is a large $N$, and $K \\simeq NP$.\n",
    "\n",
    "We also suppose that $P \\simeq p(\\mathbf{x})V$, so our approximation of density distribution has form $p(\\mathbf{x}) = \\frac{K}{NV}$. This means that $\\mathcal{R}$ should be large enough to let binomial distribution reach the peak but should also be small enough so that the density is approximately a constant.\n",
    "\n",
    "There are two ways to use this formula:\n",
    "* **Kernel Method:** Keep $V$ unchanged and determine $K$ from data\n",
    "* **K Nearest Neighbor:** Keep $K$ unchanged and determine $V$ from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Method\n",
    "Define $$k(u) = \\begin{cases}\n",
    "                    1 & |u_i| \\leq \\frac{1}{2}, i = 1, \\cdots, D\\\\\n",
    "                    0 & \\mathrm{othersize}\n",
    "                \\end{cases}$$\n",
    "\n",
    "which is an example of **kernel function**.\n",
    "\n",
    "The number of data in cube with center $\\mathbf{x}$ and length of edge to be $h$ is:\n",
    "    $$K = \\sum_{n = 1}^{N} k\\left(\\frac{\\mathbf{x} - \\mathbf{x}_n}{h}\\right)$$\n",
    "    \n",
    "So $$p(\\mathbf{x}) = \\frac{1}{N} \\sum_{n = 1}^{N} \\frac{1}{h^D} k\\left(\\frac{\\mathbf{x} - \\mathbf{x}_n}{h}\\right)$$\n",
    "\n",
    "To get a more smooth result, we can choose to use Gaussian kernel function and get\n",
    "$$p(\\mathbf{x}) = \\frac{1}{N} \\sum_{n = 1}^{N} \\frac{1}{(2\\pi h^2)^{\\frac{D}{2}}} \\exp\\left\\{-\\frac{||\\mathbf{x} - \\mathbf{x}_n||^2}{2h^2}\\right\\}$$\n",
    "\n",
    "Note that we can choose any $k(\\mathbf{u})$ if:\n",
    "\\begin{align}\n",
    "    &k(\\mathbf{u}) \\geq 0\\nonumber\\\\\n",
    "    &\\int k(\\mathbf{u})d\\mathbf{u} = 1\\nonumber\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor\n",
    "Suppose we have a dataset that $N_k$ data belongs to class $C_k$, the total number is $N$. If we want to catergorize a new $\\mathbf{x}$. Then we draw a sphere centered at $\\mathbf{x}$ that contains $K$ data points. Suppose the volume of the sphere is $V$, so\n",
    "$$p(\\mathbf{x} \\mid C_k) = \\frac{K_k}{N_kV}$$\n",
    "\n",
    "$$p(\\mathbf{x}) = \\frac{K}{NV}$$\n",
    "\n",
    "and class prior is\n",
    "\n",
    "$$p(C_k) = \\frac{N_k}{N}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$p(C_k \\mid x) = \\frac{p(\\mathbf{x} \\mid C_k)p(C_k)}{p(\\mathbf{x})} = \\frac{K_k}{K}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
